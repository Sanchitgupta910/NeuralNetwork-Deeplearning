{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z6oUWwIABp8f"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating my own dataset\n",
        "# X = (hours sleeping, hours studying), y = test score of the student\n",
        "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
        "y = np.array(([92], [86], [89]), dtype=float)"
      ],
      "metadata": {
        "id": "DkpeZwfwB0hW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale units\n",
        "X = X/np.amax(X, axis=0) #maximum of X array\n",
        "y = y/100 # maximum test score is 100"
      ],
      "metadata": {
        "id": "EoskHm8jCAVo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(object):\n",
        "    def __init__(self):\n",
        "        #parameters\n",
        "        self.inputSize = 2\n",
        "        self.outputSize = 1\n",
        "        self.hiddenSize = 3\n",
        "        \n",
        "        #weights\n",
        "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n",
        "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
        "        \n",
        "    def feedForward(self, X):\n",
        "        #forward propogation through the network\n",
        "        self.z = np.dot(X, self.W1) #dot product of X (input) and first set of weights (3x2)\n",
        "        self.z2 = self.sigmoid(self.z) #activation function\n",
        "        self.z3 = np.dot(self.z2, self.W2) #dot product of hidden layer (z2) and second set of weights (3x1)\n",
        "        output = self.sigmoid(self.z3)\n",
        "        return output\n",
        "        \n",
        "    def sigmoid(self, s, deriv=False):\n",
        "        if (deriv == True):\n",
        "            return s * (1 - s)\n",
        "        return 1/(1 + np.exp(-s))\n",
        "    \n",
        "    def backward(self, X, y, output):\n",
        "        #backward propogate through the network\n",
        "        self.output_error = y - output # error in output\n",
        "        self.output_delta = self.output_error * self.sigmoid(output, deriv=True)\n",
        "        \n",
        "        self.z2_error = self.output_delta.dot(self.W2.T) #z2 error: how much our hidden layer weights contribute to output error\n",
        "        self.z2_delta = self.z2_error * self.sigmoid(self.z2, deriv=True) #applying derivative of sigmoid to z2 error\n",
        "        \n",
        "        self.W1 += X.T.dot(self.z2_delta) # adjusting first set (input -> hidden) weights\n",
        "        self.W2 += self.z2.T.dot(self.output_delta) # adjusting second set (hidden -> output) weights\n",
        "        \n",
        "    def train(self, X, y):\n",
        "        output = self.feedForward(X)\n",
        "        self.backward(X, y, output)"
      ],
      "metadata": {
        "id": "SCNgdYHSCB9M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NN = NeuralNetwork()\n",
        "\n",
        "for i in range(1000): #trains the NN 1000 times\n",
        "    \n",
        "    NN.train(X, y)\n",
        "        \n",
        "print(\"Input: \" + str(X))\n",
        "print(\"Actual Output: \" + str(y))\n",
        "print(\"Mean Square Error: \" + str(np.mean(np.square(y - NN.feedForward(X)))))\n",
        "print(\"\\n\")\n",
        "print(\"Predicted Output: \" + str(NN.feedForward(X)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KfcDILwCOBR",
        "outputId": "de25c255-282a-4abd-e2dc-6a4ca5ad9afb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: [[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Mean Square Error: 0.0005836353965695714\n",
            "\n",
            "\n",
            "Predicted Output: [[0.88716717]\n",
            " [0.88124721]\n",
            " [0.90488179]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference:\n",
        "So as we can see that the input matrix was 0.667 and so on and the actual output that we require are 0.92, 0.86, 0.89. So after 1000 iterations the mean sq error is 0.0005836 and the predicted output is little bit close to the actual output that we require which is 0.887 which is close to 0.92, 0.881 is slightly higher than the actual output which was 0.86 and 0.904 is almost equals to the third actual output that was 0.89\n",
        "Hence we can increase the number to iteration to reduce the mean square error.\n"
      ],
      "metadata": {
        "id": "8QWhKOEBaUhm"
      }
    }
  ]
}